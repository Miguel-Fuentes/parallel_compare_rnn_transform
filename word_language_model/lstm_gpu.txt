This model has 13987678 paramaters
Namespace(batch_size=20, bptt=35, clip=0.25, cuda=True, data='./data/wikitext-2', dropout=0.2, emsize=200, epochs=6, log_interval=200, lr=20, model='LSTM', nhead=2, nhid=200, nlayers=2, onnx_export='', output_name='lstm_gpu.txt', save='model.pt', seed=1111, tied=False)
| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| epoch {epoch} | {batch}/{len(train_data) // args.bptt} batches | lr {lr} | ms/batch {elapsed * 1000 / args.log_interval} | loss {cur_loss} | ppl {math.exp(cur_loss)}| end of epoch 1 | time: 41.911481618881226s | valid loss 5.529283133531622 | valid ppl {math.exp(val_loss)}